{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2965537,"sourceType":"datasetVersion","datasetId":1818188}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# Load the Titanic dataset\ntry:\n   df = pd.read_csv('Titanic-Dataset.csv') \nexcept FileNotFoundError:\n    print(\"Error: Please ensure 'Titanic-Dataset.csv' is correctly loaded in your environment.\")\n    exit()\n\nprint(\"--- Initial Data Info ---\")\nprint(df.info())\nprint(\"\\nMissing values:\\n\", df.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Impute 'Age' (Numerical) using the median\ndf['Age'].fillna(df['Age'].median(), inplace=True)\n\n# Impute 'Embarked' (Categorical) using the mode\nmost_frequent_embarked = df['Embarked'].mode()[0]\ndf['Embarked'].fillna(most_frequent_embarked, inplace=True)\n\n# Drop 'Cabin' due to high percentage of missing values\ndf.drop('Cabin', axis=1, inplace=True)\n\nprint(\"\\nMissing values after imputation:\\n\", df.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Binary Categorical ('Sex'): Label Encoding\nle = LabelEncoder()\ndf['Sex_Encoded'] = le.fit_transform(df['Sex'])\ndf.drop('Sex', axis=1, inplace=True)\n\n# Multi-class Categorical ('Embarked'): One-Hot Encoding\ndf = pd.get_dummies(df, columns=['Embarked'], drop_first=True, prefix='Emb')\n\n# Drop object columns not needed for modeling (Name, Ticket)\ndf.drop(['Name', 'Ticket'], axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 'Fare' distribution before removal\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=df['Fare'])\nplt.title('Fare Distribution (Before Removal)')\nplt.show()\n\n# Use the IQR method to define the upper boundary for outliers\nQ1 = df['Fare'].quantile(0.25)\nQ3 = df['Fare'].quantile(0.75)\nIQR = Q3 - Q1\nupper_bound = Q3 + 1.5 * IQR\n\n# Filter out the outliers, creating an explicit deep copy\ndf_clean = df[df['Fare'] <= upper_bound].copy()\n\nprint(f\"\\nOriginal row count: {len(df)}. Rows after outlier removal: {len(df_clean)}.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Use Standardization (Z-Score Scaling) on 'Age' and 'Fare'\nscaler = StandardScaler()\ndf_clean[['Age', 'Fare']] = scaler.fit_transform(df_clean[['Age', 'Fare']])\n\nprint(\"\\n--- Final Clean Data Snapshot (First 5 Rows) ---\")\nprint(df_clean.head())\n\n# Save the final dataframe \ndf_clean.to_csv('titanic_preprocessed.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}